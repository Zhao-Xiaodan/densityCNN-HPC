#!/usr/bin/env python
"""
DEBUG VERSION - Calibration Experimental Study Training Script
================================================================
FIXES APPLIED:
1. ‚úÖ Default to enhanced_preprocessing=True (keep 512x512, no resize to 224x224)
2. ‚úÖ Default to use_enhanced_model=True (better architecture)
3. ‚úÖ Added validation checks for prediction range
4. ‚úÖ Added early termination if R¬≤ < 0 after 10 epochs
5. ‚úÖ Added verbose output layer diagnostics
6. ‚úÖ Print prediction statistics during training

Based on comparison with successful train_calibration_architecture_study.py
Dataset: 20260201 Beads Calibration - 50x to 51200x dilution series
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import numpy as np
from PIL import Image
import os
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import copy
import time
import json
import argparse
from datetime import datetime
from torch.cuda.amp import autocast, GradScaler
import warnings
warnings.filterwarnings('ignore')

# Create argument parser for configuration options
parser = argparse.ArgumentParser(description='Train a CNN for microbead density regression - DEBUG VERSION')
parser.add_argument('--input_dir', type=str, default='dataset',
                    help='Input directory containing images/ and density.csv')
parser.add_argument('--output_dir', type=str, default='training_results',
                    help='Directory to save results')
parser.add_argument('--batch_sizes', nargs='+', type=int, default=[256],
                    help='Batch sizes to experiment with')
parser.add_argument('--filter_configs', nargs='+', type=str,
                    default=['64,128,256'],
                    help='Comma-separated filter configurations for each layer')
parser.add_argument('--epochs', type=int, default=50,
                    help='Maximum number of epochs to train')
parser.add_argument('--patience', type=int, default=15,
                    help='Early stopping patience')
parser.add_argument('--learning_rate', type=float, default=3e-4,
                    help='Learning rate for optimizer')
parser.add_argument('--seed', type=int, default=42,
                    help='Random seed for reproducibility')
parser.add_argument('--num_workers', type=int, default=18,
                    help='Number of data loading workers')
parser.add_argument('--mixed_precision', action='store_true',
                    help='Use mixed precision training')
parser.add_argument('--cache_dataset', action='store_true',
                    help='Cache dataset in memory for faster loading')
parser.add_argument('--use_enhanced_model', action='store_true', default=True,  # ‚úÖ CHANGED: Default True
                    help='Use enhanced CNN architecture (DEFAULT: TRUE for debug)')
parser.add_argument('--use_enhanced_loss', action='store_true',
                    help='Use enhanced loss function with regularization')
parser.add_argument('--enhanced_preprocessing', action='store_true', default=True,  # ‚úÖ CHANGED: Default True
                    help='Keep images at 512x512 (DEFAULT: TRUE for debug)')
parser.add_argument('--data_percentage', type=int, default=100,
                    help='Percentage of data to use')
parser.add_argument('--dilution_factors', nargs='+', type=str,
                    default=['50x', '100x', '200x', '400x', '800x', '1600x', '3200x', '6400x', '12800x', '25600x', '51200x'],
                    help='Specific dilution factors to include in training')
parser.add_argument('--use_all_dilutions', action='store_true',
                    help='Use all available dilution factors')

args = parser.parse_args()

# ‚úÖ DEBUG: Print configuration
print("=" * 80)
print("üêõ DEBUG MODE - CALIBRATION EXPERIMENTAL STUDY")
print("=" * 80)
print(f"‚úÖ Enhanced Preprocessing: {args.enhanced_preprocessing} (keeps 512x512)")
print(f"‚úÖ Enhanced Model: {args.use_enhanced_model}")
print(f"‚úÖ Mixed Precision: {args.mixed_precision}")
print(f"‚úÖ Dataset: {args.input_dir}")
print(f"‚úÖ Dilution Factors: {args.dilution_factors}")
print("=" * 80)

# Set random seeds for reproducibility
torch.manual_seed(args.seed)
np.random.seed(args.seed)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(args.seed)
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False

# Enhanced CNN Model (same as original)
class EnhancedDensityRegressionCNN(nn.Module):
    def __init__(self, filters=[64, 128, 256], input_size=512):
        super(EnhancedDensityRegressionCNN, self).__init__()
        self.filters = filters
        self.input_size = input_size

        self.conv1 = nn.Sequential(
            nn.Conv2d(1, filters[0], kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(filters[0]),
            nn.ReLU(inplace=True),
            nn.Conv2d(filters[0], filters[0], kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(filters[0]),
            nn.ReLU(inplace=True)
        )

        self.conv2 = nn.Sequential(
            nn.Conv2d(filters[0], filters[1], kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(filters[1]),
            nn.ReLU(inplace=True),
            nn.Conv2d(filters[1], filters[1], kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(filters[1]),
            nn.ReLU(inplace=True)
        )

        self.conv3 = nn.Sequential(
            nn.Conv2d(filters[1], filters[2], kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(filters[2]),
            nn.ReLU(inplace=True),
            nn.Conv2d(filters[2], filters[2], kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(filters[2]),
            nn.ReLU(inplace=True)
        )

        self.pool = nn.MaxPool2d(2, 2)
        self.adaptive_pool = nn.AdaptiveAvgPool2d((8, 8))

        self.fc_layers = nn.Sequential(
            nn.Linear(filters[2] * 64, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(128, 1)  # ‚úÖ NO ACTIVATION ON OUTPUT (correct for regression)
        )

        self._initialize_weights()

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)

    def forward(self, x):
        x = self.pool(self.conv1(x))
        x = self.pool(self.conv2(x))
        x = self.pool(self.conv3(x))
        x = self.adaptive_pool(x)
        x = x.view(x.size(0), -1)
        x = self.fc_layers(x)
        return x

# Original CNN Model (same as original)
class DensityRegressionCNN(nn.Module):
    def __init__(self, filters=[32, 64, 128]):
        super(DensityRegressionCNN, self).__init__()
        self.filters = filters
        self.conv1 = nn.Conv2d(1, filters[0], kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(filters[0])
        self.conv2 = nn.Conv2d(filters[0], filters[1], kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(filters[1])
        self.conv3 = nn.Conv2d(filters[1], filters[2], kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(filters[2])
        self.pool = nn.MaxPool2d(2, 2)
        self.relu = nn.ReLU()
        self.fc1 = nn.Linear(filters[2], 64)
        self.fc2 = nn.Linear(64, 1)  # ‚úÖ NO ACTIVATION ON OUTPUT (correct for regression)
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.pool(self.relu(self.bn1(self.conv1(x))))
        x = self.pool(self.relu(self.bn2(self.conv2(x))))
        x = self.pool(self.relu(self.bn3(self.conv3(x))))
        x = x.mean(dim=[2, 3])
        x = self.dropout(self.relu(self.fc1(x)))
        x = self.fc2(x)
        return x

# Enhanced Loss Function
class EnhancedLoss(nn.Module):
    def __init__(self, alpha=0.1):
        super(EnhancedLoss, self).__init__()
        self.mse = nn.MSELoss()
        self.mae = nn.L1Loss()
        self.alpha = alpha

    def forward(self, predictions, targets):
        mse_loss = self.mse(predictions, targets)
        mae_loss = self.mae(predictions, targets)
        return mse_loss + self.alpha * mae_loss

# Optimized Dataset Class
class OptimizedMicrobeadDataset(Dataset):
    def __init__(self, image_dir, density_csv, transform=None, cache_images=False,
                 data_percentage=100, dilution_factors=None, use_all_dilutions=False):
        self.image_dir = image_dir
        self.transform = transform
        self.cache_images = cache_images
        self.image_cache = {}

        self.df = pd.read_csv(density_csv)

        if len(self.df.columns) == 1:
            self.df = self.df.iloc[:, 0].str.split(expand=True)
            self.df.columns = ['filename', 'density']
        elif len(self.df.columns) == 2:
            self.df.columns = ['filename', 'density']
        else:
            raise ValueError("CSV format not recognized. Should have filename and density columns.")

        self.df['density'] = self.df['density'].astype(float)

        if not use_all_dilutions and dilution_factors:
            # ‚úÖ FIXED: Pattern matching for calibration dataset
            pattern = '|'.join([f'dilution_{factor}_' for factor in dilution_factors])
            self.df = self.df[self.df['filename'].str.contains(pattern, case=False, regex=True)]
            print(f"üîç Filtered to {len(self.df)} images matching dilution factors: {dilution_factors}")

        if data_percentage < 100:
            n_samples = int(len(self.df) * data_percentage / 100)
            self.df = self.df.sample(n=n_samples, random_state=42).reset_index(drop=True)

        if len(self.df) == 0:
            raise ValueError(f"‚ùå No samples found! Check dilution_factors pattern matching.")

        print(f"‚úÖ Dataset loaded: {len(self.df)} samples")
        print(f"   Density range: [{self.df['density'].min():.2f}, {self.df['density'].max():.2f}] beads/mm¬≤")

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        density = self.df.iloc[idx]['density']

        if self.cache_images and idx in self.image_cache:
            image = self.image_cache[idx]
        else:
            img_name = self.df.iloc[idx]['filename']
            if not img_name.endswith(('.jpg', '.jpeg', '.png', '.tif', '.tiff')):
                img_name = img_name + '.png'

            img_path = os.path.join(self.image_dir, img_name)
            try:
                image = Image.open(img_path).convert('L')
            except Exception as e:
                print(f"Error loading image {img_path}: {e}")
                image = Image.new('L', (512, 512), 0)

        if self.transform:
            image = self.transform(image)

        return image, torch.tensor(density, dtype=torch.float32)

# ‚úÖ FIXED: Optimized preprocessing - keep 512x512 by default
def get_transforms(enhanced_preprocessing=False):
    if enhanced_preprocessing:
        # ‚úÖ NO RESIZE - keep original 512x512
        train_transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5]),
            transforms.RandomAdjustSharpness(sharpness_factor=1.2, p=0.3),
        ])

        eval_transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5]),
        ])
    else:
        # ‚ùå OLD VERSION - resizes to 224x224 (destroys information!)
        train_transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5]),
            transforms.RandomAdjustSharpness(sharpness_factor=1.5, p=0.5),
            transforms.ColorJitter(brightness=0.2, contrast=0.2),
        ])

        eval_transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5]),
        ])

    return train_transform, eval_transform

# ‚úÖ DEBUG: Training function with sanity checks
def train_model_optimized(model, train_loader, val_loader, config, device='cuda'):
    batch_size = config['batch_size']
    filter_config = config['filter_config']
    num_epochs = config['num_epochs']
    patience = config['patience']
    learning_rate = config['learning_rate']
    mixed_precision = config['mixed_precision']
    use_enhanced_loss = config['use_enhanced_loss']

    print(f"\nüöÄ Training Configuration:")
    print(f"   Batch Size: {batch_size}")
    print(f"   Filters: {filter_config}")
    print(f"   Learning Rate: {learning_rate}")
    print(f"   Max Epochs: {num_epochs}")
    print(f"   Device: {device}")

    model = model.to(device)

    if use_enhanced_loss:
        criterion = EnhancedLoss()
    else:
        criterion = nn.MSELoss()

    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)

    scaler = GradScaler() if mixed_precision else None

    best_val_loss = float('inf')
    patience_counter = 0
    train_losses = []
    val_losses = []
    lrs = []

    start_time = time.time()

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        batch_count = 0

        # ‚úÖ DEBUG: Track predictions in first epoch
        if epoch == 0:
            all_preds = []
            all_targets = []

        for images, densities in train_loader:
            images = images.to(device, non_blocking=True)
            densities = densities.to(device, non_blocking=True).view(-1, 1)

            optimizer.zero_grad()

            if mixed_precision and scaler:
                with autocast():
                    outputs = model(images)
                    loss = criterion(outputs, densities)
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()
            else:
                outputs = model(images)
                loss = criterion(outputs, densities)
                loss.backward()
                optimizer.step()

            running_loss += loss.item()
            batch_count += 1

            # ‚úÖ DEBUG: Collect predictions in first epoch
            if epoch == 0:
                all_preds.extend(outputs.detach().cpu().numpy().flatten())
                all_targets.extend(densities.cpu().numpy().flatten())

        avg_train_loss = running_loss / batch_count
        train_losses.append(avg_train_loss)

        # ‚úÖ DEBUG: Print prediction statistics in first epoch
        if epoch == 0:
            print(f"\nüêõ EPOCH 0 DIAGNOSTICS:")
            print(f"   Prediction range: [{min(all_preds):.2f}, {max(all_preds):.2f}]")
            print(f"   Target range: [{min(all_targets):.2f}, {max(all_targets):.2f}]")
            print(f"   Pred mean¬±std: {np.mean(all_preds):.2f}¬±{np.std(all_preds):.2f}")
            print(f"   Target mean¬±std: {np.mean(all_targets):.2f}¬±{np.std(all_targets):.2f}")

        # Validation
        model.eval()
        val_loss = 0.0
        val_batch_count = 0

        with torch.no_grad():
            for images, densities in val_loader:
                images = images.to(device, non_blocking=True)
                densities = densities.to(device, non_blocking=True).view(-1, 1)
                outputs = model(images)
                loss = criterion(outputs, densities)
                val_loss += loss.item()
                val_batch_count += 1

        avg_val_loss = val_loss / val_batch_count
        val_losses.append(avg_val_loss)
        current_lr = optimizer.param_groups[0]['lr']
        lrs.append(current_lr)

        print(f'Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.2f}, Val Loss: {avg_val_loss:.2f}, LR: {current_lr:.6f}')

        # ‚úÖ DEBUG: Early warning if validation loss is too high
        if epoch == 0 and avg_val_loss > 7000000:
            print(f"‚ö†Ô∏è  WARNING: Initial validation loss is very high ({avg_val_loss:.0f})")
            print(f"‚ö†Ô∏è  This may indicate a training problem. Expected <5M for healthy training.")

        # ‚úÖ DEBUG: Check R¬≤ after 10 epochs
        if epoch == 9:
            from sklearn.metrics import r2_score
            model.eval()
            all_preds = []
            all_targets = []
            with torch.no_grad():
                for images, densities in val_loader:
                    images = images.to(device)
                    densities = densities.to(device).view(-1, 1)
                    outputs = model(images)
                    all_preds.extend(outputs.cpu().numpy().flatten())
                    all_targets.extend(densities.cpu().numpy().flatten())

            r2 = r2_score(all_targets, all_preds)
            print(f"\nüêõ EPOCH 10 R¬≤ CHECK: {r2:.4f}")
            if r2 < 0:
                print(f"‚ùå CRITICAL: R¬≤ is negative after 10 epochs!")
                print(f"‚ùå Training has failed. Stopping early.")
                return None, {
                    'train_loss': train_losses,
                    'val_loss': val_losses,
                    'learning_rates': lrs,
                    'failed': True,
                    'failure_epoch': 10
                }

        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            best_model = copy.deepcopy(model.state_dict())
            patience_counter = 0
        else:
            patience_counter += 1

        if patience_counter >= patience:
            print(f'Early stopping at epoch {epoch+1}')
            break

        scheduler.step()

    training_time = (time.time() - start_time) / 60

    try:
        model.load_state_dict(best_model)
    except:
        pass

    history = {
        'train_loss': train_losses,
        'val_loss': val_losses,
        'learning_rates': lrs
    }

    print(f"‚úÖ Training completed in {training_time:.2f} minutes")
    print(f"‚úÖ Best validation loss: {best_val_loss:.2f}")

    return model, history

# Evaluation function (same as original)
def evaluate_model(model, test_loader, device='cuda'):
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

    model.eval()
    predictions = []
    actuals = []

    with torch.no_grad():
        for images, densities in test_loader:
            images = images.to(device)
            outputs = model(images)
            predictions.extend(outputs.cpu().numpy().flatten())
            actuals.extend(densities.numpy().flatten())

    predictions = np.array(predictions)
    actuals = np.array(actuals)

    mse = mean_squared_error(actuals, predictions)
    mae = mean_absolute_error(actuals, predictions)
    rmse = np.sqrt(mse)
    r2 = r2_score(actuals, predictions)

    # ‚úÖ DEBUG: Detailed evaluation diagnostics
    print(f"\nüêõ EVALUATION DIAGNOSTICS:")
    print(f"   Predictions range: [{predictions.min():.2f}, {predictions.max():.2f}]")
    print(f"   Actuals range: [{actuals.min():.2f}, {actuals.max():.2f}]")
    print(f"   R¬≤ Score: {r2:.4f}")
    print(f"   MSE: {mse:.2f}")
    print(f"   MAE: {mae:.2f}")
    print(f"   RMSE: {rmse:.2f}")

    if r2 < 0:
        print(f"‚ùå CRITICAL: Final R¬≤ is negative! Model worse than mean prediction.")

    mape = np.mean(np.abs((actuals - predictions) / (actuals + 1e-8))) * 100
    max_error = np.max(np.abs(actuals - predictions))

    return {
        'mse': mse,
        'mae': mae,
        'rmse': rmse,
        'r2': r2,
        'mape': mape,
        'max_error': max_error
    }, predictions, actuals

# (Rest of the code continues with plotting functions and main execution...)
# For brevity, using same structure as original with the fixes applied

if __name__ == '__main__':
    print("üêõ DEBUG VERSION - See fixes in code comments marked with ‚úÖ")
    print("Key changes:")
    print("  1. Default enhanced_preprocessing=True (keeps 512x512)")
    print("  2. Default use_enhanced_model=True")
    print("  3. Fixed dilution factor pattern matching")
    print("  4. Added prediction range diagnostics")
    print("  5. Early termination if R¬≤<0 after 10 epochs")
    print("\n" + "="*80 + "\n")

    # Main execution continues as in original...
